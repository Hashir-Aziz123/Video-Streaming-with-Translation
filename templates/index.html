<!DOCTYPE html>
<html>
<head>
    <title>Minimal AI Video</title>
    <style>
        body { background: #111; color: white; display: flex; flex-direction: column; align-items: center; }
        #video-grid { display: flex; gap: 10px; }
        video { width: 400px; height: 300px; background: black; border: 1px solid #333; }
        #captions { font-size: 24px; color: yellow; margin-top: 20px; font-family: sans-serif; }
    </style>
    <script src="https://unpkg.com/peerjs@1.5.2/dist/peerjs.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
</head>
<body>
    <h2>Gemini Video Call</h2>
    <div id="video-grid">
        <video id="my-video" muted autoplay playsinline></video>
        <video id="user-video" autoplay playsinline></video>
    </div>
    <div id="captions">Waiting for speech...</div>

   <script>
        const socket = io();
        const myVideo = document.getElementById('my-video');
        const userVideo = document.getElementById('user-video');
        const captionsDiv = document.getElementById('captions'); // Get the caption box

        const peer = new Peer();

        navigator.mediaDevices.getUserMedia({ video: true, audio: true }).then(stream => {
            myVideo.srcObject = stream;

            peer.on('call', call => {
                call.answer(stream);
                call.on('stream', userVideoStream => {
                    userVideo.srcObject = userVideoStream;
                });
            });

            socket.on('user-connected', userId => {
                const call = peer.call(userId, stream);
                call.on('stream', userVideoStream => {
                    userVideo.srcObject = userVideoStream;
                });
            });

            // --- SPEECH RECOGNITION FIX ---
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (SpeechRecognition) {
                const recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true; // This is crucial
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    captionsDiv.innerText = "ðŸ”´ Listening... (Speak now)";
                };

                recognition.onresult = (event) => {
                    const current = event.resultIndex;
                    const transcript = event.results[current][0].transcript;
                    
                    // 1. SHOW WHAT YOU ARE SAYING LIVE (Grey text)
                    if (!event.results[current].isFinal) {
                        captionsDiv.style.color = '#888'; // Grey for "thinking"
                        captionsDiv.innerText = transcript + "...";
                    } 
                    
                    // 2. SEND WHEN DONE (Yellow text)
                    else {
                        captionsDiv.style.color = 'yellow';
                        captionsDiv.innerText = "ðŸŽ¤ Sending: " + transcript;
                        socket.emit('audio-chunk', { text: transcript, target_lang: 'Spanish' });
                    }
                };

                recognition.onerror = (event) => {
                    console.error("Speech Error:", event.error);
                    captionsDiv.innerText = "âŒ Error: " + event.error;
                };

                recognition.start();
            } else {
                alert("This browser does not support Speech API. Please use Google Chrome.");
            }
        });

        peer.on('open', id => {
            socket.emit('join-room', { userId: id });
        });

        socket.on('translation-result', data => {
            // Show the result in Blue/Green
            captionsDiv.innerHTML = `<span style="color: #aaa">${data.original}</span> <br/> <span style="color: #4af; font-size:30px">âž¤ ${data.translated}</span>`;
        });
    </script>
</body>
</html>